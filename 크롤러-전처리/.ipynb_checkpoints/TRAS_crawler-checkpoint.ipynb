{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/twinstae/tripReviewAnalysisSystem/blob/master/%ED%81%AC%EB%A1%A4%EB%9F%AC-%EC%A0%84%EC%B2%98%EB%A6%AC/TRAS_crawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zciHbS535CM6",
    "outputId": "8f44ef50-11dd-45c3-96d5-eb1f05fadc2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 911kB 2.8MB/s eta 0:00:01\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q selenium\n",
    "!pip install -q bs4\n",
    "!pip install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZx-9HwI4WLS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MP2betB4YeO"
   },
   "outputs": [],
   "source": [
    "#키를 파일 이름으로 저장\n",
    "def data_to_csv(dict_n, name):\n",
    "    '''\n",
    "    입력 : 딕셔너리 데이터\n",
    "    출력 : csv파일 형태로 원시 자료 폴더에 출력.\n",
    "    '''\n",
    "    attraction = dict_n.keys\n",
    "    address = dict_n.values\n",
    "    data = [attraction, address]\n",
    "    git_address = 'C:/Users/taehee/Documents/GitHub'\n",
    "    attractions_df = pd.DataFrame(data)\n",
    "    attractions_df.to_csv(git_address + '/tripReviewAnalysisSystem/크롤러-전처리/원시자료/' + name +'.csv', mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJipUMCV4Zku"
   },
   "outputs": [],
   "source": [
    "def reviews(sample_size):\n",
    "    '''\n",
    "    단위 테스트 성공. 개발 완료.\n",
    "    입력 : 표본 리뷰의 숫자자.\n",
    "    맥락 : 리뷰를 추출할 즐길거리 페이지에 있다.\n",
    "    출력 : 한 즐길거리에 대한 리뷰를 모아놓은 데이터 프레임\n",
    "\n",
    "    각 리뷰에서 새로운 항목을 추출하고 싶다면, columns와 for문을 모두 수정해야한다.\n",
    "    '''\n",
    "    reviews = []\n",
    "    columns = ['star_point','title','text','Date of experience']\n",
    "    #,'reviewer_address'\n",
    "        \n",
    "        \n",
    "    #리뷰 크기를 텍스트로 찾아와, 콤마를 제거하여, 정수형으로 저장.\n",
    "    review_size_text = driver.find_element_by_class_name('attractions-community-content-TabBarContent__tabCount--2hTdj').text\n",
    "    review_size = int(re.sub(',','', str(review_size_text)))\n",
    "\n",
    "    n = 5\n",
    "    count = 0\n",
    "    while n < sample_size:\n",
    "        try:\n",
    "            foot = driver.find_element_by_class_name('location-review-review-list-parts-ReviewScrollController__container--3XtvE')\n",
    "            show_more = foot.find_element_by_tag_name('button')  \n",
    "            driver.execute_script(\"arguments[0].click();\", show_more)\n",
    "            n += 5\n",
    "        except:\n",
    "            if count > 3:\n",
    "                break\n",
    "            count +=1\n",
    "            time.sleep(2)\n",
    "                \n",
    "    review_cards = driver.find_elements_by_class_name('location-review-card-Card__ui_card--2Mri0')\n",
    "\n",
    "    for review_card in review_cards:\n",
    "        try:\n",
    "            read_more = review_card.find_element_by_class_name('location-review-review-list-parts-ExpandableReview__cta--2mR2g')\n",
    "            read_more.click()\n",
    "        except:\n",
    "            print('error')\n",
    "            continue\n",
    "    \n",
    "    # 드라이버 \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    review_elements = soup.find_all(class_ = 'location-review-card-Card__ui_card--2Mri0 location-review-card-Card__card--o3LVm location-review-card-Card__section--NiAcw')\n",
    "    \n",
    "    for review_element in review_elements:\n",
    "        try:\n",
    "            review = [\n",
    "                int(review_element.find('span',class_='ui_bubble_rating')['class'][1][-2:]) / 10,\n",
    "                review_element.find('a', class_='location-review-review-list-parts-ReviewTitle__reviewTitleText--2tFRT').find('span').find('span').text,\n",
    "                review_element.find('q', class_='location-review-review-list-parts-ExpandableReview__reviewText--gOmRC').find('span').text,\n",
    "                review_element.find('span', class_='location-review-review-list-parts-EventDate__event_date--1epHa').contents[1]\n",
    "                #,review_element.find('span', class_='social-member-common-MemberHometown__hometown--3kM9S').contents[1]\n",
    "            ]\n",
    "        except IndexError:\n",
    "            #아무도 helpful이나 vote를 누르지 않은 에러, 무시하고 계속\n",
    "            continue\n",
    "        except AttributeError:\n",
    "            #주소를 공개하지 않는 에러, 무시하고 계속\n",
    "            continue\n",
    "        reviews.append(review)\n",
    "\n",
    "    return pd.DataFrame(reviews, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_reviews():\n",
    "    \n",
    "    columns = ['title','text']\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    member_review = soup.find('div',class_='pageNumbers')\n",
    "    group_size = member_review.find_all('a')[-1].text\n",
    "    \n",
    "    if group_size >= 60 :\n",
    "        group_count = 60\n",
    "    else :\n",
    "        group_count = grop_size\n",
    "        \n",
    "    review_count = 1\n",
    "    \n",
    "    while review_count < group_count :\n",
    "        \n",
    "        review_cards = driver.find_elements_by_class_name('location-review-card-Card__ui_card--2Mri0')\n",
    "\n",
    "\n",
    "        read_more = review_cards[0].find_element_by_class_name('location-review-review-list-parts-ExpandableReview__cta--2mR2g')\n",
    "        read_more.click()\n",
    "            \n",
    "        time.sleep(2)\n",
    "        \n",
    "        # 드라이버 \n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        review_elements = soup.find_all(class_ = 'location-review-card-Card__ui_card--2Mri0 location-review-card-Card__card--o3LVm location-review-card-Card__section--NiAcw')\n",
    "\n",
    "        for review_element in review_elements:\n",
    "            try:\n",
    "                review = [\n",
    "                    int(review_element.find('span',class_='ui_bubble_rating')['class'][1][-2:]) / 10,\n",
    "                    review_element.find('q', class_='location-review-review-list-parts-ExpandableReview__reviewText--gOmRC').find('span').text\n",
    "                ]\n",
    "            except IndexError:\n",
    "                #아무도 helpful이나 vote를 누르지 않은 에러, 무시하고 계속\n",
    "                continue\n",
    "            except AttributeError:\n",
    "                #주소를 공개하지 않는 에러, 무시하고 계속\n",
    "                continue\n",
    "            reviews.append(review)\n",
    "\n",
    "        review_count += 1\n",
    "\n",
    "        str_review_count = str(review_count)\n",
    "\n",
    "        member_next = member_review.find_element_by_link_text(str_review_count)\n",
    "        driver.execute_script(\"arguments[0].click();\", member_next)\n",
    "        time.sleep(3)\n",
    "    df = pd.DataFrame(reviews, columns = columns)\n",
    "\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "I37lXHEM5ril",
    "outputId": "c495a88b-c66c-41c3-89fe-55ba64b2101c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data_test = [names, location]\\n\\ndf_list = pd.DataFrame(data_test, columns = columns)\\ndf_list.to_csv('crawler test.csv')\\n\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_address():\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    contact = soup.find_all(class_ = 'attractions-contact-card-ContactCard__contactRow--3Ih6v')\n",
    "    address_block = contact[0]\n",
    "    address_spans = address_block.contents\n",
    "    address_span = address_spans[1]\n",
    "    address = address_span.text\n",
    "    return address\n",
    "\n",
    "\"\"\"data_test = [names, location]\n",
    "\n",
    "df_list = pd.DataFrame(data_test, columns = columns)\n",
    "df_list.to_csv('crawler test.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#해당 여행지의 페이지로 이동한 뒤에 호출\n",
    "def crawl_attraction_by_types():\n",
    "    '''\n",
    "    현재 페이지에 있는 리뷰들을 여행자 타입별로 데이터프레임의 딕셔너리로 만들어 반환\n",
    "    '''\n",
    "    attraction_dict = {}\n",
    "    for traveler_type, check in checkbox_dict.items():\n",
    "        print(traveler_type)\n",
    "        check.click()\n",
    "        data = crawl_reviews()\n",
    "        attraction_dict[traveler_type] = data\n",
    "        check.click()\n",
    "    return attraction_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nEsPaNEJ4aP-"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D4CQ7nrs4dG-"
   },
   "outputs": [],
   "source": [
    "def load_attraction(link, function):\n",
    "    '''\n",
    "    단위 테스트 성공. 개발 완료.\n",
    "    입력 : 어떤 즐길거리 번호 int, 이름 string 예: \"Gyeongbokgung Palace\"\n",
    "    출력 : 어트랙션의 리뷰 모음. data.frame\n",
    "    '''\n",
    "    #새 창을 열고 링크로 간다.\n",
    "    # 슬립...매우매우중요이거없으면무조건에러남.이거하나로3시간머리싸맸음.\n",
    "    \n",
    "    time.sleep(2)\n",
    "    original_window = driver.current_window_handle\n",
    "    driver.execute_script(\"arguments[0].click();\", link)\n",
    "    \n",
    "    for window_handle in driver.window_handles:\n",
    "        if window_handle != original_window:\n",
    "            driver.switch_to.window(window_handle)\n",
    "            break\n",
    "    \n",
    "    #즐길거리 별로 샘플사이즈를 어떻게 정할 것인지?    \n",
    "    result = function()\n",
    "\n",
    "    #창을 닫고 리스트 창으로 돌아간다\n",
    "    driver.close();\n",
    "    driver.switch_to.window(original_window)\n",
    "    driver.current_window_handle;\n",
    "    \n",
    "    return result\n",
    "    #result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1AyFsH6b4flb"
   },
   "outputs": [],
   "source": [
    "def load_page(start, end, function):\n",
    "    '''\n",
    "    단위 테스트 성공. 개발 완료.\n",
    "    입력 : 크롤링할 페이지 내 시작 번호와 끝 번호\n",
    "    출력 : 페이지의 리뷰들을 csv파일로 출력\n",
    "    '''\n",
    "\n",
    "    #모든 여행지의 리스트를 만든다\n",
    "    is_first = True\n",
    "    print(\"I am in the load_page\")\n",
    "    if driver.current_url == 'https://www.tripadvisor.com/Attractions-g294197-Activities-Seoul.html':\n",
    "        main_page = driver.find_element_by_class_name('attractions-attraction-overview-main-TopPOIs__container--3eHZU')\n",
    "        attraction_elements = main_page.find_elements_by_class_name(\"attractions-attraction-overview-pois-PoiInfo__info--239IR\")\n",
    "        is_first = True\n",
    "    else:\n",
    "        main_page = driver.find_element_by_class_name('scrollAdMain')\n",
    "        attraction_elements = main_page.find_elements_by_class_name('listing_info')\n",
    "        is_first = False\n",
    "    print(\"I found the elements!\")\n",
    "\n",
    "    attraction_names = []\n",
    "    for attraction_element in attraction_elements[start:end]:      \n",
    "        if is_first:\n",
    "            link = attraction_element.find_element_by_tag_name('h3')\n",
    "            attraction_name = link.text[link.text.find('.')+2 :]\n",
    "        else:\n",
    "            div_class = attraction_element.find_element_by_class_name('tracking_attraction_title')\n",
    "            link = div_class.find_element_by_tag_name('a')\n",
    "            attraction_name = link.text\n",
    "        attraction_names.append((attraction_name, link))   \n",
    "    print(\"I found the attraction_names\")\n",
    "    \n",
    "    file_name = str(start) +\"~\"+str(end)+\"_\"+ function.__name__\n",
    "    \n",
    "    attraction_dict = {}\n",
    "    for attraction_name, link in attraction_names:\n",
    "        if len(attraction_dict) < end:\n",
    "            stime = time.time()\n",
    "            \n",
    "            # 여행지 크롤링\n",
    "            attraction_dict[attraction_name] = load_attraction(link, function)\n",
    "            \n",
    "            print(attraction_name,  \" \" + str(time.time() -stime) + \"초 걸림 \")\n",
    "            if len(attraction_dict) % 5 == 0:   \n",
    "                value_type = type(list(attraction_dict.values())[0])\n",
    "                if value_type == type('s'):\n",
    "                    data_to_csv(attraction_dict, name = file_name)\n",
    "                    print(\"저장했어요!\")\n",
    "                if value_type == type({}):                  \n",
    "                    for attraction_name, reviews_by_type_dict in attraction_dict.items():                \n",
    "                        for trav_type, type_df in reviews_by_type_dict.items():                     \n",
    "                            file_name = attraction_name +'_'+trav_type+'_df'\n",
    "                            git_address = 'C:/Users/taehee/Documents/GitHub'\n",
    "                            type_df.to_csv(git_address + '/tripReviewAnalysisSystem/크롤러-전처리/원시자료/' + file_name +'.csv', mode = 'w')\n",
    "                    print(\"저장했어요!\")\n",
    "        else:\n",
    "            data_to_csv(attraction_dict, name = file_name)\n",
    "            print(\"저장했어요!\")\n",
    "            break\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attraction_dict ={'taeheegung': 'name'}\n",
    "value_type = type(list(attraction_dict.values())[0])\n",
    "value_type == type('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NK8UrXP64nnk"
   },
   "outputs": [],
   "source": [
    "def func_is_first_page(driver):\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        show = driver.find_element_by_class_name('attractions-attraction-overview-main-TopPOIs__see_more--2Vsb-')\n",
    "        driver.execute_script(\"arguments[0].click();\", show)\n",
    "        is_first_page = True\n",
    "        print(\"it is first page!\")\n",
    "    except NoSuchElementException:\n",
    "        print('continue!')\n",
    "        is_first_page = False\n",
    "    except:\n",
    "        print(\"exception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x6RZ8B_K4gyL"
   },
   "outputs": [],
   "source": [
    "def get_start_page(soup, start, end):\n",
    "    result_page = 1\n",
    "    try:\n",
    "        page_numbers = driver.find_element_by_class_name('attractions-attraction-overview-main-Pagination__container--PUXGq')\n",
    "    except NoSuchElementException:\n",
    "        show = driver.find_element_by_class_name('attractions-attraction-overview-main-TopPOIs__see_more--2Vsb-')\n",
    "        driver.execute_script(\"arguments[0].click();\", show)\n",
    "        page_numbers = driver.find_element_by_class_name('attractions-attraction-overview-main-Pagination__container--PUXGq')\n",
    "        \n",
    "    if start // 30 > 0:\n",
    "        if start // 30 > 6:\n",
    "            target_num = 6\n",
    "        else:\n",
    "            target_num = (start // 30) + 1\n",
    "        target_page = page_numbers.find_element_by_link_text(str(target_num))\n",
    "        time.sleep(1)\n",
    "        driver.execute_script(\"arguments[0].click();\", target_page)\n",
    "        time.sleep(1)\n",
    "        result_page = target_num\n",
    "        page_numbers = driver.find_element_by_class_name('attractions-attraction-overview-main-Pagination__container--PUXGq')\n",
    "        is_first_page = False\n",
    "    else:\n",
    "        page_numbers_soup = soup.find(\"div\", class_='attractions-attraction-overview-main-Pagination__container--PUXGq') \n",
    "        result_page = page_numbers_soup.find_all(\"span\")[1].text\n",
    "        page_numbers = driver.find_element_by_class_name('attractions-attraction-overview-main-Pagination__container--PUXGq')\n",
    "        \n",
    "    return int(result_page), page_numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fnuZ002T4umh"
   },
   "outputs": [],
   "source": [
    "def crawl_pages(is_first_page, start, end, function):\n",
    "    keep_going = True    \n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    print(\"I made a soup\")\n",
    "    \n",
    "    selected_page, page_numbers = get_start_page(soup, start, end)\n",
    "\n",
    "    while keep_going:\n",
    "        # 현재 페이지 번호 알아내기\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        print(\"I made a soup\")\n",
    "            \n",
    "                # 시작점이 뒷 페이지면 지나간다\n",
    "        if start <= selected_page * 30:\n",
    "            strat_in_page = start-(selected_page-1)*30\n",
    "            if strat_in_page < 0:\n",
    "                strat_in_page = 0\n",
    "            assert strat_in_page <= 30\n",
    "            \n",
    "            end_in_page = end-(selected_page-1)*30\n",
    "            if end_in_page > 30:\n",
    "                end_in_page = 30                \n",
    "            assert 0 <= end_in_page\n",
    "            if is_first_page:\n",
    "                is_first_page = False\n",
    "                \n",
    "            load_page(strat_in_page, end_in_page, function)\n",
    "        \n",
    "        # 끝나는 지점을 지나갔으면 루프를 끝낸다.\n",
    "        if (selected_page - 1) * 30 >= end:\n",
    "            keep_going = False\n",
    "            break\n",
    "            \n",
    "        print(\"I find the current page\")\n",
    "\n",
    "        # 다음 페이지로 넘어가기\n",
    "        time.sleep(1)\n",
    "        selected_page += 1\n",
    "        next_page = page_numbers.find_element_by_link_text(str(selected_page))\n",
    "        driver.execute_script(\"arguments[0].click();\", next_page)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9lxsfGG4wYl"
   },
   "outputs": [],
   "source": [
    "def crawl_function(start, end, function):\n",
    "    '''\n",
    "    입력 : 크롤링할 즐길거리의 시작 번호와 끝 번호\n",
    "    출력 : 해당 구간의 즐길거리 리뷰들csv로 출력\n",
    "    '''    \n",
    "        \n",
    "    #처음 한 번만 see more을 누른다.\n",
    "    is_first_page = func_is_first_page(driver)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    crawl_pages(is_first_page, start, end, function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "colab_type": "code",
    "id": "v7QdW4Lh4waN",
    "outputId": "365f8fd7-e0f7-448e-ddbd-dbd3619aeb21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: use options instead of chrome_options\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# 언어를 영어 캐나다로 설정. 이래야 show more버튼이 나오는 줄 알았는데...\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"lang=en-CA\")\n",
    "#이미지를 보지 않음\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "\n",
    "driver_address = r'C:\\Users\\Jeong\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(driver_address, chrome_options=options)\n",
    "wait = WebDriverWait(driver, timeout=2)\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "#원래 있던 리스트 창을 저장해둔다\n",
    "time.sleep(1)\n",
    "driver.get('https://www.tripadvisor.ca/Attractions-g294197-Activities-Seoul.html')\n",
    "\n",
    "\n",
    "#dict_n() => load_page() => load_reviews() => reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is first page!\n",
      "I made a soup\n",
      "I made a soup\n",
      "I am in the load_page\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".scrollAdMain\"}\n  (Session info: chrome=81.0.4044.129)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-fac246e4f6d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcrawl_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrawl_attraction_by_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-4e8d59682a49>\u001b[0m in \u001b[0;36mcrawl_function\u001b[1;34m(start, end, function)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mcrawl_pages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_first_page\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-394ae55133fb>\u001b[0m in \u001b[0;36mcrawl_pages\u001b[1;34m(is_first_page, start, end, function)\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mis_first_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mload_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrat_in_page\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_in_page\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# 끝나는 지점을 지나갔으면 루프를 끝낸다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-b6445d36019d>\u001b[0m in \u001b[0;36mload_page\u001b[1;34m(start, end, function)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mis_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mmain_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'scrollAdMain'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mattraction_elements\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_page\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'listing_info'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mis_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_class_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'foo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \"\"\"\n\u001b[1;32m--> 564\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m             'value': value})['value']\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".scrollAdMain\"}\n  (Session info: chrome=81.0.4044.129)\n"
     ]
    }
   ],
   "source": [
    "crawl_function(start= 0, end= 5, function = crawl_attraction_by_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNS1fuYzbVTs5TBXBpg+qZO",
   "include_colab_link": true,
   "name": "TRAS_crawler.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
