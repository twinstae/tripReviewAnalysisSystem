{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/twinstae/tripReviewAnalysisSystem/blob/master/%ED%81%AC%EB%A1%A4%EB%9F%AC-%EC%A0%84%EC%B2%98%EB%A6%AC/TRAS_crawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zciHbS535CM6",
    "outputId": "8f44ef50-11dd-45c3-96d5-eb1f05fadc2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 911kB 2.8MB/s eta 0:00:01\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q selenium\n",
    "!pip install -q bs4\n",
    "!pip install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZx-9HwI4WLS"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException, ElementClickInterceptedException, StaleElementReferenceException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5 import uic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MP2betB4YeO"
   },
   "outputs": [],
   "source": [
    "#키를 파일 이름으로 저장\n",
    "def data_to_csv(dict_n, name):\n",
    "    '''\n",
    "    입력 : 딕셔너리 데이터\n",
    "    출력 : csv파일 형태로 원시 자료 폴더에 출력.\n",
    "    '''\n",
    "    attraction = dict_n.keys\n",
    "    address = dict_n.values\n",
    "    data = [attraction, address]\n",
    "    git_address = 'C:/Users/taehee/Documents/GitHub'\n",
    "    attractions_df = pd.DataFrame(data)\n",
    "    attractions_df.to_csv(git_address + '/tripReviewAnalysisSystem/크롤러-전처리/원시자료/' + name +'.csv', mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJipUMCV4Zku"
   },
   "outputs": [],
   "source": [
    "def reviews(sample_size):\n",
    "    '''\n",
    "    단위 테스트 성공. 개발 완료.\n",
    "    입력 : 표본 리뷰의 숫자자.\n",
    "    맥락 : 리뷰를 추출할 즐길거리 페이지에 있다.\n",
    "    출력 : 한 즐길거리에 대한 리뷰를 모아놓은 데이터 프레임\n",
    "\n",
    "    각 리뷰에서 새로운 항목을 추출하고 싶다면, columns와 for문을 모두 수정해야한다.\n",
    "    '''\n",
    "    reviews = []\n",
    "    columns = ['star_point','title','text','Date of experience']\n",
    "    #,'reviewer_address'\n",
    "        \n",
    "        \n",
    "    #리뷰 크기를 텍스트로 찾아와, 콤마를 제거하여, 정수형으로 저장.\n",
    "    review_size_text = driver.find_element_by_class_name('attractions-community-content-TabBarContent__tabCount--2hTdj').text\n",
    "    review_size = int(re.sub(',','', str(review_size_text)))\n",
    "\n",
    "    n = 5\n",
    "    count = 0\n",
    "    while n < sample_size:\n",
    "        try:\n",
    "            foot = driver.find_element_by_class_name('location-review-review-list-parts-ReviewScrollController__container--3XtvE')\n",
    "            show_more = foot.find_element_by_tag_name('button')  \n",
    "            driver.execute_script(\"arguments[0].click();\", show_more)\n",
    "            n += 5\n",
    "        except:\n",
    "            if count > 3:\n",
    "                break\n",
    "            count +=1\n",
    "            time.sleep(2)\n",
    "                \n",
    "    review_cards = driver.find_elements_by_class_name('location-review-card-Card__ui_card--2Mri0')\n",
    "\n",
    "    for review_card in review_cards:\n",
    "        try:\n",
    "            read_more = review_card.find_element_by_class_name('location-review-review-list-parts-ExpandableReview__cta--2mR2g')\n",
    "            read_more.click()\n",
    "        except:\n",
    "            print('error')\n",
    "            continue\n",
    "    \n",
    "    # 드라이버 \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    review_elements = soup.find_all(class_ = 'location-review-card-Card__ui_card--2Mri0 location-review-card-Card__card--o3LVm location-review-card-Card__section--NiAcw')\n",
    "    \n",
    "    for review_element in review_elements:\n",
    "        try:\n",
    "            review = [\n",
    "                int(review_element.find('span',class_='ui_bubble_rating')['class'][1][-2:]) / 10,\n",
    "                review_element.find('a', class_='location-review-review-list-parts-ReviewTitle__reviewTitleText--2tFRT').find('span').find('span').text,\n",
    "                review_element.find('q', class_='location-review-review-list-parts-ExpandableReview__reviewText--gOmRC').find('span').text,\n",
    "                review_element.find('span', class_='location-review-review-list-parts-EventDate__event_date--1epHa').contents[1]\n",
    "                #,review_element.find('span', class_='social-member-common-MemberHometown__hometown--3kM9S').contents[1]\n",
    "            ]\n",
    "        except IndexError:\n",
    "            #아무도 helpful이나 vote를 누르지 않은 에러, 무시하고 계속\n",
    "            continue\n",
    "        except AttributeError:\n",
    "            #주소를 공개하지 않는 에러, 무시하고 계속\n",
    "            continue\n",
    "        reviews.append(review)\n",
    "\n",
    "    return pd.DataFrame(reviews, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_reviews():\n",
    "    \n",
    "    columns = ['title','text']\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        member_review = driver.find_element_by_class_name('pageNumbers')\n",
    "        group_size = int(member_review.find_elements_by_tag_name('a')[-1].text)\n",
    "        m_review = 1\n",
    "        \n",
    "    except:\n",
    "        group_size = 2\n",
    "        m_review = 2\n",
    "        \n",
    "    if group_size >= 60 :\n",
    "        group_count = 60\n",
    "    else :\n",
    "        group_count = group_size\n",
    "        \n",
    "    review_count = 1\n",
    "    reviews = []\n",
    "    \n",
    "    while review_count < group_count:\n",
    "        \n",
    "        review_cards = driver.find_elements_by_class_name('location-review-card-Card__ui_card--2Mri0')\n",
    "        time.sleep(3)\n",
    "        try:\n",
    "            read_more = review_cards[0].find_element_by_class_name('location-review-review-list-parts-ExpandableReview__cta--2mR2g')\n",
    "            driver.execute_script(\"arguments[0].click();\", read_more)\n",
    "        except ElementNotInteractableException:\n",
    "            print(\"I already Click the read more buttons!\")\n",
    "        except ElementClickInterceptedException:\n",
    "            print(\"I can't click the read more buttons!\")\n",
    "        except StaleElementReferenceException:\n",
    "            print(\"I can't click the read more buttons!\")\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "            \n",
    "        time.sleep(2)\n",
    "        \n",
    "        # 드라이버 \n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        review_elements = soup.find_all(class_ = 'location-review-card-Card__ui_card--2Mri0 location-review-card-Card__card--o3LVm location-review-card-Card__section--NiAcw')\n",
    "\n",
    "        for review_element in review_elements:\n",
    "            try:\n",
    "                review = [\n",
    "                    int(review_element.find('span',class_='ui_bubble_rating')['class'][1][-2:]) / 10,\n",
    "                    review_element.find('q', class_='location-review-review-list-parts-ExpandableReview__reviewText--gOmRC').find('span').text\n",
    "                ]\n",
    "            except IndexError:\n",
    "                #아무도 helpful이나 vote를 누르지 않은 에러, 무시하고 계속\n",
    "                continue\n",
    "            except AttributeError:\n",
    "                #주소를 공개하지 않는 에러, 무시하고 계속\n",
    "                continue\n",
    "            reviews.append(review)\n",
    "\n",
    "        review_count += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        str_review_count = str(review_count)\n",
    "        if m_review == 1:\n",
    "            try:\n",
    "                member_next = member_review.find_element_by_link_text(str_review_count)\n",
    "                driver.execute_script(\"arguments[0].click();\", member_next)\n",
    "            except StaleElementReferenceException:\n",
    "                print(\"No reivew page!\")\n",
    "                break\n",
    "            except NoSuchElementException:\n",
    "                print(\"No reivew page!\")\n",
    "                break\n",
    "        else:\n",
    "            print (\"No reivew page number\")\n",
    "            break\n",
    "        time.sleep(3)\n",
    "    df = pd.DataFrame(reviews, columns = columns)\n",
    "\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "I37lXHEM5ril",
    "outputId": "c495a88b-c66c-41c3-89fe-55ba64b2101c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data_test = [names, location]\\n\\ndf_list = pd.DataFrame(data_test, columns = columns)\\ndf_list.to_csv('crawler test.csv')\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_address():\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    contact = soup.find_all(class_ = 'attractions-contact-card-ContactCard__contactRow--3Ih6v')\n",
    "    address_block = contact[0]\n",
    "    address_spans = address_block.contents\n",
    "    address_span = address_spans[1]\n",
    "    address = address_span.text\n",
    "    return address\n",
    "\n",
    "\"\"\"data_test = [names, location]\n",
    "\n",
    "df_list = pd.DataFrame(data_test, columns = columns)\n",
    "df_list.to_csv('crawler test.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#해당 여행지의 페이지로 이동한 뒤에 호출\n",
    "def crawl_attraction_by_types():\n",
    "    '''\n",
    "    현재 페이지에 있는 리뷰들을 여행자 타입별로 데이터프레임의 딕셔너리로 만들어 반환\n",
    "    '''\n",
    "    \n",
    "    review_panel = driver.find_element_by_class_name('location-review-review-list-parts-ReviewFilters__filters_wrap--y1t86')    \n",
    "    process1 = review_panel.find_elements_by_class_name('is-shown-at-tablet')\n",
    "    pp.pprint([we.text for we in process1])\n",
    "    checkbox_list = process1[0].find_elements_by_tag_name('label')\n",
    "    pp.pprint([we.text for we in checkbox_list])    \n",
    "    \n",
    "    checkbox_dict = {checkbox.text: checkbox for checkbox in checkbox_list}\n",
    "    print(\"I found the checkboxes!\")\n",
    "    pp.pprint(checkbox_dict)\n",
    "    attraction_dict = {}\n",
    "    for traveler_type, check in checkbox_dict.items():\n",
    "        print(traveler_type)\n",
    "        \n",
    "        check.click()\n",
    "        time.sleep(2)\n",
    "        data = crawl_reviews()\n",
    "        attraction_dict[traveler_type] = data\n",
    "        check.click()\n",
    "    return attraction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D4CQ7nrs4dG-"
   },
   "outputs": [],
   "source": [
    "def load_attraction(link, function):\n",
    "    '''\n",
    "    단위 테스트 성공. 개발 완료.\n",
    "    입력 : 어떤 즐길거리 번호 int, 이름 string 예: \"Gyeongbokgung Palace\"\n",
    "    출력 : 어트랙션의 리뷰 모음. data.frame\n",
    "    '''\n",
    "    #새 창을 열고 링크로 간다.\n",
    "    # 슬립...매우매우중요이거없으면무조건에러남.이거하나로3시간머리싸맸음.\n",
    "    \n",
    "    time.sleep(2)\n",
    "    original_window = driver.current_window_handle\n",
    "    driver.execute_script(\"arguments[0].click();\", link)\n",
    "    \n",
    "    for window_handle in driver.window_handles:\n",
    "        if window_handle != original_window:\n",
    "            driver.switch_to.window(window_handle)\n",
    "            break\n",
    "    \n",
    "    #즐길거리 별로 샘플사이즈를 어떻게 정할 것인지?    \n",
    "    result = function()\n",
    "\n",
    "    #창을 닫고 리스트 창으로 돌아간다\n",
    "    driver.close();\n",
    "    driver.switch_to.window(original_window)\n",
    "    driver.current_window_handle;\n",
    "    \n",
    "    return result\n",
    "    #result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1AyFsH6b4flb"
   },
   "outputs": [],
   "source": [
    "def load_page(start, end):\n",
    "    '''\n",
    "    단위 테스트 성공. 개발 완료.\n",
    "    입력 : 크롤링할 페이지 내 시작 번호와 끝 번호\n",
    "    출력 : 페이지의 리뷰들을 csv파일로 출력\n",
    "    '''\n",
    "\n",
    "    #모든 여행지의 리스트를 만든다\n",
    "    is_first = True\n",
    "    \n",
    "    print(\"I am in the load_page\")\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        main_fake = driver.find_element_by_class_name('attractions-attraction-overview-main-TopPOIs__container--3eHZU')\n",
    "        main_page = soup.find(class_ = 'attractions-attraction-overview-main-TopPOIs__container--3eHZU')\n",
    "        attraction_names = main_page.find_all(name='h3')\n",
    "        attraction_srcs = main_page.find_all(name='img')\n",
    "        is_first = True\n",
    "    except NoSuchElementException :\n",
    "        main_page = soup.find(class_ = 'attractions-attraction-filtered-common-attraction-filtered-common__listingsContainer--2cOBG')\n",
    "        attraction_names = main_page.find_all(name='h2')\n",
    "        attraction_srcs = main_page.find_all(name='img')\n",
    "        is_first = False\n",
    "    print(\"I found the elements!\")\n",
    "       \n",
    "\n",
    "    # 구현 방법 모두 긁고난 뒤 for문으로 리스트 저장, 이미지 파일의 이름을 어트랙션의 이름으로 저장 \n",
    "    \n",
    "    name_error = 1\n",
    "    attraction_elements = []\n",
    "    for attraction_name, attraction_src in zip(attraction_names[start:end], attraction_srcs[start:end]) :  \n",
    "        str_name = str(attraction_name)\n",
    "        str_src = str(attraction_src)\n",
    "        if is_first:\n",
    "            if name_error < 11:\n",
    "                name_start = str_name.find('<!-- -->') + 8\n",
    "                name_end = str_name.find('</h3>') \n",
    "                attr_name = str_name[name_start:name_end]\n",
    "            else:\n",
    "                name_start = str_name.find('.') + 2\n",
    "                name_end = str_name.find('</h3>') \n",
    "                attr_name = str_name[name_start:name_end]\n",
    "            # 1페이지 이름 추출, 1 ~ 10, 11 ~ 30 따로 추출    \n",
    "            src_start = str_src.find('150w') + 6\n",
    "            url_w = str_src[src_start:]\n",
    "            src_end = url_w.find('w, https') -4\n",
    "            attr_src = url_w[:src_end]\n",
    "            name_error += 1\n",
    "            # 1페이지 src 추출\n",
    "        else:\n",
    "            name_start = str_name.find('<h2>') + 4\n",
    "            name_end = str_name.find('</h2>')\n",
    "            attr_name = str_name[name_start:name_end]\n",
    "            # 다른 페이지 이름 추출\n",
    "            src_start = str_src.find('150w') + 5\n",
    "            url_w = str_src[src_start:]\n",
    "            src_end = url_w.find('w,https') - 4\n",
    "            attr_src = url_w[:src_end]\n",
    "            if attr_src == \"https://media-cdn.tripadvisor.com/media/daodao/photo-s/05/33/4f/b4/caption.jpg 29\":\n",
    "                end_number_src = attr_src.find('29') - 1\n",
    "                attr_src = attr_src[:end_number_src]\n",
    "            # 다른 페이지 src 추출\n",
    "        attraction_elements.append((attr_name, attr_src))   \n",
    "    print(\"I found the attraction_elements!\")\n",
    "    \n",
    "    for attr_name, attr_src in attraction_elements[start:end]:\n",
    "        img_src = attr_src\n",
    "        img_name = attr_name\n",
    "        urllib.request.urlretrieve(img_src, r'C:\\Users\\Jeong\\attractionimage/' + img_name +'.jpg')\n",
    "        print(img_name + \"이미지 저장 완료!\")\n",
    "    # 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attraction_dict ={'taeheegung': 'name'}\n",
    "value_type = type(list(attraction_dict.values())[0])\n",
    "value_type == type('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NK8UrXP64nnk"
   },
   "outputs": [],
   "source": [
    "def func_is_first_page(driver):\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        show = driver.find_element_by_class_name('attractions-attraction-overview-main-TopPOIs__see_more--2Vsb-')\n",
    "        driver.execute_script(\"arguments[0].click();\", show)\n",
    "        is_first_page = True\n",
    "        print(\"it is first page!\")\n",
    "    except NoSuchElementException:\n",
    "        print('continue!')\n",
    "        is_first_page = False\n",
    "    except:\n",
    "        print(\"exception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x6RZ8B_K4gyL"
   },
   "outputs": [],
   "source": [
    "def get_start_page(soup, start, end):\n",
    "    result_page = 1\n",
    "    try:\n",
    "        page_numbers = driver.find_element_by_class_name('attractions-attraction-overview-main-Pagination__container--PUXGq')\n",
    "    except:\n",
    "        page_numbers = driver.find_element_by_class_name('attractions-attraction-filtered-common-FilteredPagination__pagination--15y40')\n",
    "        print('버튼들을 찾았다!')\n",
    "        \n",
    "    if start // 30 > 0:\n",
    "        if start // 30 > 6:\n",
    "            target_num = 6\n",
    "        else:\n",
    "            target_num = (start // 30) + 1\n",
    "        target_page = page_numbers.find_element_by_link_text(str(target_num))\n",
    "        time.sleep(1)\n",
    "        driver.execute_script(\"arguments[0].click();\", target_page)\n",
    "        time.sleep(1)\n",
    "        result_page = target_num\n",
    "        try:\n",
    "            page_numbers = driver.find_element_by_class_name('attractions-attraction-overview-main-Pagination__container--PUXGq')\n",
    "        except NoSuchElementException:\n",
    "            page_numbers = driver.find_element_by_class_name('attractions-attraction-filtered-common-FilteredPagination__pagination--15y40')\n",
    "        is_first_page = False\n",
    "    else:\n",
    "        page_numbers_soup = soup.find(\"div\", class_='attractions-attraction-overview-main-Pagination__container--PUXGq') \n",
    "        result_page = page_numbers_soup.find_all(\"span\")[1].text\n",
    "        page_numbers = driver.find_element_by_class_name('attractions-attraction-overview-main-Pagination__container--PUXGq')\n",
    "        \n",
    "    return int(result_page), page_numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fnuZ002T4umh"
   },
   "outputs": [],
   "source": [
    "def crawl_pages(is_first_page, start, end):\n",
    "    keep_going = True    \n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    print(\"I made a soup\")\n",
    "    \n",
    "    selected_page, page_numbers = get_start_page(soup, start, end)\n",
    "\n",
    "    while keep_going:\n",
    "        # 현재 페이지 번호 알아내기\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        print(\"I made a soup\")\n",
    "            \n",
    "                # 시작점이 뒷 페이지면 지나간다\n",
    "        if start <= selected_page * 30:\n",
    "            strat_in_page = start-(selected_page-1)*30\n",
    "            if strat_in_page < 0:\n",
    "                strat_in_page = 0\n",
    "            assert strat_in_page <= 30\n",
    "            \n",
    "            end_in_page = end-(selected_page-1)*30\n",
    "            if end_in_page > 30:\n",
    "                end_in_page = 30                \n",
    "            assert 0 <= end_in_page\n",
    "            if is_first_page:\n",
    "                is_first_page = False\n",
    "                \n",
    "            load_page(strat_in_page, end_in_page)\n",
    "        \n",
    "        # 끝나는 지점을 지나갔으면 루프를 끝낸다.\n",
    "        if (selected_page - 1) * 30 >= end:\n",
    "            keep_going = False\n",
    "            break\n",
    "            \n",
    "        print(\"I find the current page\")\n",
    "\n",
    "        # 다음 페이지로 넘어가기\n",
    "        time.sleep(1)\n",
    "        selected_page += 1\n",
    "        next_page = page_numbers.find_element_by_link_text(str(selected_page))\n",
    "        driver.execute_script(\"arguments[0].click();\", next_page)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9lxsfGG4wYl"
   },
   "outputs": [],
   "source": [
    "def crawl_function(start, end):\n",
    "    '''\n",
    "    입력 : 크롤링할 즐길거리의 시작 번호와 끝 번호\n",
    "    출력 : 해당 구간의 즐길거리 리뷰들csv로 출력\n",
    "    '''    \n",
    "        \n",
    "    #처음 한 번만 see more을 누른다.\n",
    "    is_first_page = func_is_first_page(driver)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    crawl_pages(is_first_page, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "colab_type": "code",
    "id": "v7QdW4Lh4waN",
    "outputId": "365f8fd7-e0f7-448e-ddbd-dbd3619aeb21"
   },
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"lang=en-CA\")\n",
    "options.add_argument('window-size=1920x1080')\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "driver_address = r'C:\\Users\\Jeong\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(driver_address, chrome_options=options)\n",
    "wait = WebDriverWait(driver, timeout=2)\n",
    "driver.implicitly_wait(5)\n",
    "# tripadvisor에 접근한다.\n",
    "driver.get('https://www.tripadvisor.com/Attractions-g294197-Activities-Seoul.html')\n",
    "#driver.get('https://www.tripadvisor.com/Attractions-g294197-Activities-oa30-Seoul.html')\n",
    "#원래 있던 리스트 창을 저장해둔다\n",
    "original_window = driver.current_window_handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception\n"
     ]
    }
   ],
   "source": [
    "crawl_function(start= 60, end= 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "form_class = uic.loadUiType(\"lineeditTest.ui\")[0]\n",
    "\n",
    "class WindowClass(QMainWindow, form_class) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.setupUi(self)\n",
    "\n",
    "        #버튼에 기능을 할당하는 코드\n",
    "        self.btn_changeText.clicked.connect(self.find_tip)\n",
    "\n",
    "    def find_tip(self) :\n",
    "        #self.lineedit이름.setText(\"String\")\n",
    "        #Lineedit의 글자를 바꾸는 메서드\n",
    "        key = self.lineedit_Test.text()\n",
    "        self.lbl_textHere.setPlainText(tip.error(key))\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    app = QApplication(sys.argv)\n",
    "    myWindow = WindowClass()\n",
    "    myWindow.show()\n",
    "    app.exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_load_page()\n",
    "    \n",
    "    is_first = True\n",
    "    print(\"I am in the load_page\")\n",
    "    try:\n",
    "        main_page = driver.find_element_by_class_name('attractions-attraction-overview-main-TopPOIs__container--3eHZU')\n",
    "        attraction_elements = main_page.find_elements_by_class_name(\"_1SVhvMXu\")\n",
    "        is_first = True\n",
    "    except NoSuchElementException :\n",
    "        main_page = driver.find_element_by_class_name('attractions-attraction-filtered-common-attraction-filtered-common__listingsContainer--2cOBG')\n",
    "        attraction_elements = main_page.find_elements_by_class_name('_1MKm6PFo')\n",
    "        is_first = False\n",
    "    print(\"I found the elements!\")\n",
    "\n",
    "    attraction_names = []\n",
    "    for attraction_element in attraction_elements[start:end]:      \n",
    "        if is_first:\n",
    "            link = attraction_element.find_element_by_tag_name('img')\n",
    "            attraction_name = link.find_element_by_class_name('src').text\n",
    "        else:\n",
    "            link = attraction_element.find_element_by_tag_name('h3')\n",
    "            attraction_name = link.text\n",
    "        attraction_names.append((attraction_name, link))   \n",
    "    print(\"I found the attraction_names\")\n",
    "    print(attraction_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './static/Gyeongbokgung_Palace.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-dd7b6ab356a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Gyeongbokgung_Palace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./static/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mAttraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./static/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;31m# Handle temporary file setup.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m             \u001b[0mtfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mtfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNamedTemporaryFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './static/Gyeongbokgung_Palace.jpg'"
     ]
    }
   ],
   "source": [
    "\n",
    "src = \"https://media-cdn.tripadvisor.com/media/photo-o/1b/39/64/f7/caption.jpg\"\n",
    "\n",
    "name = \"Gyeongbokgung_Palace\"\n",
    "\n",
    "b = urllib.request.urlretrieve(src, './static/' + name + '.jpg')\n",
    "Attraction.image = Image.open('./static/' + name + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_save()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNS1fuYzbVTs5TBXBpg+qZO",
   "include_colab_link": true,
   "name": "TRAS_crawler.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
